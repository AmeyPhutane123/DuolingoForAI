WIP1

<p align="center">
  <img src="https://img.shields.io/badge/Streamlit-ğŸŸ¢-brightgreen" alt="Streamlit Badge" />
  <img src="https://img.shields.io/badge/HuggingFace-ğŸ¤—-yellow" alt="HuggingFace Badge" />
</p>

# DuolingoForAI

> **A free, Duolingoâ€‘style Streamlit app that teaches what tokenization is by letting you type text and instantly see tokens, input IDs, attention masks, and subword splits using a fast Hugging Face tokenizer.**

---

## ğŸš€ Why this exists
LLMs operate on tokens, not words. Understanding tokenization helps you write better prompts, control costs, and predict model behavior. This app visualizes how text becomes modelâ€‘ready inputsâ€”making the invisible visible!

Streamlit makes it easy to ship interactive lessons and demos on the web, for free, with zero setup.

---

## ğŸ® What it does
- **Interactive playground:** Type a sentence and instantly visualize tokens, input IDs, attention masks, and optional character offsets/word alignment from fast tokenizers.
- **Miniâ€‘quiz:** â€œGuess the token countâ€ with instant feedback and a celebratory animation to keep learning fun.
- **Duolingo feel:** Themed UI via `.streamlit/config.toml` with bright colors, rounded cards, and playful microâ€‘interactions.

---

## ğŸ› ï¸ Tech stack
- **Streamlit** for UI and state management
- **Hugging Face Transformers** AutoTokenizer (fast) for tokenization and offsets mapping
- **Optional hosting:** Streamlit Community Cloud or Hugging Face Spaces for free, public access

---

## ğŸ“ Project structure
- `app.py` â€” main Streamlit app. Keep UI logic here and import small helpers if needed.
- `.streamlit/config.toml` â€” theme (colors, fonts) for a consistent â€œDuolingoâ€ vibe on local and cloud runs.
- `requirements.txt` â€” pinned versions for reliable cloud builds.

---

## ğŸ–¥ï¸ Local setup
Create a virtual environment, install dependencies, and run locally with hotâ€‘reload:

```sh
python -m venv .venv
# Activate your environment
# On Windows:
.venv\Scripts\activate
# On Mac/Linux:
source .venv/bin/activate
pip install -r requirements.txt
streamlit run app.py
```

---

## ğŸŒ Deploy options
- **Streamlit Community Cloud:** Connect the repo and deploy; manage and view logs from the â€œManage appâ€ panel.
- **Hugging Face Spaces:** Add README and config; Spaces reads the repo and builds automatically. Use the READMEâ€™s YAML header to set title/emoji/thumbnail if desired.

---

## ğŸ“¦ Requirements (example)
```
streamlit==1.36.0
transformers==4.43.3
tokenizers==0.19.1
torch==2.3.1
huggingface-hub==0.24.6
```
*Pinned versions help avoid cloudâ€‘build incompatibilities.*

---

## ğŸ§‘â€ğŸ’» How it works (under the hood)
- `AutoTokenizer.from_pretrained("distilbert-base-uncased", use_fast=True)` loads a fast tokenizer with offset mapping.
- The app calls `tokenizer(text, return_offsets_mapping=True, add_special_tokens=True)` and renders:
  - tokens via `convert_ids_to_tokens`
  - input_ids and attention_mask from the BatchEncoding
  - offsets/word_ids (when available) to highlight subword spans in the original text.

---

## ğŸ—ºï¸ Roadmap
- **Lesson 1 (this app):** Tokenization basics and subword intuition.
- **Upcoming lessons:** Transformers basics, sentiment demo, fineâ€‘tuning primer, and RAG walkthroughâ€”all using the same Streamlit + free hosting setup.

---

## ğŸ… Badges and Space metadata (optional)
Add a â€œDuplicate this Spaceâ€ or â€œOpen in Spacesâ€ badge to the README for easy sharing using the Hugging Face badges set.
Add a YAML header to the README to customize the Spaceâ€™s title, emoji, and thumbnail.

---

## ğŸ™ Acknowledgments
Built with Streamlitâ€™s recommended app structure and theming for approachable, productionâ€‘friendly GenAI demos.
Tokenization concepts and APIs from Hugging Face Transformers documentation.

---

## ğŸ“š Related
- What specific features should the README explain for our Streamlit GenAI app
- How should we describe the recommended folder structure and utils usage
- Which setup steps and secrets handling must I include for deployment
- Why should we document prompt templates and LLM utility patterns
- How can I show examples of running and testing the app locally
